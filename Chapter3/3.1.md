# <p align="right">3. 从张量开始</p>
***

>本章包括：  
&emsp;&emsp;- 理解张量--PyTorch中的基本数据结构  
&emsp;&emsp;- 张量的索引和运算  
&emsp;&emsp;- 与NumPy多维数组的交互操作  
&emsp;&emsp;- 将计算转移到GPU上以提高速度 

&emsp;&emsp;在上一章中，我们介绍了深度学习所实现的众多应用中的一部分。它们无一例外地包括获取某种形式的数据(如图像或文本)，并产生另一种形式的数据(如标签、数字或更多图像、文本)。从这个角度来看，深度学习其实就是构建一个能够将数据从一种表示形式转化为另一种表示形式的系统。这种转换是通过从一系列展示所需映射的例子中提取共性来驱动的。例如，系统可能会注意到狗的一般形状和金毛犬的典型颜色。通过结合这两种图像属性，系统可以将具有给定形状和颜色的图像正确地映射到**金毛犬**标签上，而不是**黑色的实验室**(或就此而言，黄褐色的山猫猫)。由此产生的系统可以消耗大量的类似输入，并为这些输入产生有意义的输出。

&emsp;&emsp;该过程首先将我们的输入转换为浮点数。我们将在第4章中介绍如何将图像像素转换为数字，如图3.1中的第一步所示(以及许多其他类型的数据)。但在这之前，在本章中，我们将学习如何在 PyTorch 中使用 **tensors (张量)** 来处理所有的浮点数。

## 3.1 <span id='chap3-1'>浮点数世界</span>

由于浮点数是网络处理信息的方式，我们需要一种方法将我们想要处理的现实世界的数据编码成网络可以消化的东西，然后将输出的数据解码成我们可以理解和使用的内容。

<center>图3.1 深度神经网络学习如何将输入表示转化为输出表示。(注：神经元和输出的数量不成比例。)</center>

<div align=center>
<img src="../img/Chap3/3-1.png" />
</div>

深度神经网络通常会分阶段学习从一种形式的数据到另一种形式的数据的转换，这意味着每个阶段之间的部分转换数据可以被认为是一系列中间表示。对于图像识别来说，早期的表示可以是边缘检测或某些纹理（如毛皮）等。更深层次的表示可以捕获更复杂的结构，如耳朵、鼻子或眼睛。

一般来说，这种中间表示是浮点数的集合，它对输入进行表征，并以一种有助于描述输入如何映射到神经网络的输出的方式来捕获数据的结构。这种表征是针对当前任务的，可以从相关示例中学习的。这些浮点数的集合及其操作是现代人工智能的核心--我们将在本书中看到几个这样的示例。

请务必牢记，这些中间表示（如图3.1第二步所示）是将输入与前一层神经元的权重相结合的结果。每个中间表示对于之前的输入都是唯一的。

在开始将数据转换为浮点输入之前，我们首先必须对PyTorch如何处理和存储数据--作为输入、中间表示和输出--有一些扎实的了解。本章将专门讨论这个问题。

为此，PyTorch引入了一个基本的数据结构：**tensor (张量)**。我们在第2章对预训练网络进行推理时，已经碰到了张量。对于那些来自数学、物理学或工程学的人来说，张量这个术语与空间、参照系以及它们之间的变换的概念捆绑在一起。无论好坏，这些概念在这里均不适用。在深度学习的上下文中，**张量是指向量和矩阵到任意维数的泛化**，如图3.2所示。这一概念的另一个名称是**multidimensional array (多维数组)**。张量的维数与用于引用张量内标量值的索引数一致。

<center>图3.2 张量是在PyTorch中表示数据的基础</center>

<div align=center>
<img src="../img/Chap3/3-2.png" />
</div>


PyTorch不是唯一处理多维数组的库。NumPy是迄今为止最受欢迎的多维数组库，可以说它现在已经成为数据科学的通用语言。PyTorch的特点是与NumPy的无缝互操作性，这为它带来了与Python中其他科学库的一流集成，比如SciPy (www.scipy.org) 、Scikit-Learning (https://scikit-learn.org) 和Pandas (https://pandas.pydata.org) 。

与NumPy数组相比，PyTorch张量具有一些超强的功能，例如能够在图形处理单元(GPU)上执行非常快速的操作、在多个设备或机器上分布式操作，以及跟踪创建它们的计算图的能力。这些都是实现现代深度学习库的重要功能。

在本章中，我们将介绍PyTorch张量，其中涵盖了它的相关基础知识，以便为本书其余部分的工作做准备。首先，我们将学习如何使用PyTorch张量库操纵张量。这包括诸如如何将数据存储在内存中，如何在固定时间内对任意大的张量执行某些操作以及前面提到的NumPy互操作性和GPU加速。如果要使张量成为我们编程工具箱中的首选工具，了解张量的功能和API是非常重要的。在下一章中，我们将充分利用这些知识，并学习如何以能够通过神经网络进行学习的方式表示几种不同类型的数据。

## 3.2 <span id='chap3-2'>张量：多维数组</span>

我们已经了解到，张量是PyTorch中的基本数据结构。 张量是一个数组：即一种存储数字集合的数据结构，这些数字可以使用索引单独访问，并且可以使用多个索引进行索引。

### 3.2.1 从Python列表到PyTorch张量

让我们看看列表索引的实际应用，这样我们就可以将其与张量索引进行比较。在Python中取一个包含三个数字的列表(.code/p1ch3/1_tensors.ipynb)：

```python
# In[1]:
a = [1.0, 2.0, 1.0]
```

我们可以使用对应的从零开始的索引来访问列表的第一个元素：

```python
# In[2]:
a[0]
 
# Out[2]:
1.0
 
# In[3]:
a[2] = 3.0
a
 
# Out[3]:
[1.0, 2.0, 3.0]
```

对于处理数字向量的简单 Python 程序来说，使用 Python 列表来存储向量是很常见的，比如二维线的坐标。正如我们将在下一章中所看到的，使用更有效的张量数据结构，可以表示许多类型的数据--从图像到时间序列，甚至是句子。通过定义张量上的操作(我们将在本章中探讨其中一些操作)，即使是使用高级（但不是特别快速）的语言（例如Python），我们也可以同时高效地切片和操作数据。












## 3.3 <span id='chap3-3'>索引张量</span>
## 3.4 <span id='chap3-4'>命名张量</span>
## 3.5 <span id='chap3-5'>张量元素类型</span>
## 3.6 <span id='chap3-6'>张量API</span>
## 3.7 <span id='chap3-7'>张量：存储的风景</span>
## 3.8 <span id='chap3-8'>张量元数据：尺寸、偏移和步长</span>
## 3.9 <span id='chap3-9'>移动张量至GPU</span>
## 3.10 <span id='chap3-10'>NumPy互操作性</span>
## 3.11 <span id='chap3-11'>广义张量也是张量</span>
## 3.12 <span id='chap3-12'>序列化张量</span>
## 3.13 <span id='chap3-13'>结论</span>
## 3.14 <span id='chap3-14'>练习</span>
## 3.15 <span id='chap3-15'>小结</span>

---